import sounddevice as sd
from scipy.io.wavfile import write
import librosa
import numpy as np
import json
from sklearn.metrics.pairwise import cosine_similarity

# === GHI Ã‚M ===
def record_audio(filename="recorded.wav", duration=12, fs=44100):
    print("ğŸ™ï¸ Äang ghi Ã¢m...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()
    write(filename, fs, audio)
    print(f"âœ… Ghi xong. LÆ°u táº¡i {filename}")

# === TRÃCH MFCC + TEMPO + CENTROID ===
def extract_features(file_path):
    """Extract MFCC, tempo, and spectral centroid from an audio file."""
    print("extract_features of", file_path)
    audio, sr = librosa.load(file_path, sr=None)

    # TÃ­nh MFCC
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    # mfcc_mean = mfcc.mean(axis=1).toList() # Normal MFCC
    mfcc_mean = extract_mfcc_pro(file_path).tolist() # Pro MFCC
    # mfcc_mean = extract_mfcc_ultra(file_path).tolist() # Ultra MFCC

    # Tempo (rhythm)
    tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)
    tempo = float(tempo) if isinstance(tempo, np.ndarray) else tempo

    # Spectral Centroid (brightness/tone)
    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
    centroid_mean = np.mean(spectral_centroid)

    return mfcc_mean, tempo, centroid_mean


# === Táº¢I DATABASE ===
def load_database(json_path):
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)

# ğŸ”¹ sr â€“ Sampling Rate
# Máº·c Ä‘á»‹nh: 44100 Hz (chuáº©n CD)
# LÃ  táº§n sá»‘ láº¥y máº«u khi load file â†’ quyáº¿t Ä‘á»‹nh Ä‘á»™ phÃ¢n giáº£i táº§n sá»‘
# CÃ ng cao â†’ giá»¯ Ä‘Æ°á»£c nhiá»u táº§n sá»‘ cao (Ã¢m sÃ¡ng, chi tiáº¿t)
# ğŸ“Œ Gá»£i Ã½:
# 22050 â†’ nháº¹, nhanh
# 44100 â†’ chi tiáº¿t, full phá»• 0â€“22kHz

# ğŸ”¹ n_mfcc â€“ Sá»‘ há»‡ sá»‘ MFCC
# Máº·c Ä‘á»‹nh: 40
# LÃ  sá»‘ lÆ°á»£ng Mel-Frequency Cepstral Coefficients báº¡n muá»‘n trÃ­ch xuáº¥t
# Má»—i frame MFCC sáº½ cÃ³ n_mfcc giÃ¡ trá»‹
# ğŸ“Œ Gá»£i Ã½:
# 13 â†’ truyá»n thá»‘ng (nháº­n diá»‡n giá»ng)
# 20â€“26 â†’ phá»• biáº¿n cho nháº¡c
# 40 â†’ giÃ u thÃ´ng tin (dÃ¹ng cho ML hoáº·c nháº¡c phá»©c táº¡p)
#
# ğŸ”¹ n_fft â€“ Cá»­a sá»• FFT
# Máº·c Ä‘á»‹nh: 4096
# LÃ  kÃ­ch thÆ°á»›c khung (sá»‘ máº«u) khi thá»±c hiá»‡n biáº¿n Ä‘á»•i Fourier
# CÃ ng lá»›n â†’ Ä‘á»™ phÃ¢n giáº£i táº§n sá»‘ cÃ ng cao, nhÆ°ng kÃ©m chi tiáº¿t theo thá»i gian
# ğŸ“Œ Gá»£i Ã½:
# 1024 â†’ tá»‘t cho real-time
# 2048 â†’ phá»• thÃ´ng
# 4096 â†’ chi tiáº¿t cao vá» táº§n sá»‘ ğŸ¯
#
# ğŸ”¹ hop_length â€“ BÆ°á»›c trÆ°á»£t
# Máº·c Ä‘á»‹nh: 256 (tá»©c ~5.8ms vá»›i sr=44100)
# LÃ  sá»‘ máº«u nháº£y qua má»—i láº§n trÆ°á»£t cá»­a sá»•
# Quyáº¿t Ä‘á»‹nh Ä‘á»™ phÃ¢n giáº£i theo thá»i gian
# ğŸ“Œ Gá»£i Ã½:
# 512 â†’ mÆ°á»£t, nháº¹
# 256 â†’ chi tiáº¿t hÆ¡n (Ä‘áº·c biá»‡t khi hÃ¡t hoáº·c huÃ½t)
#
# ğŸ”¹ use_delta â€“ ThÃªm delta MFCC
# Máº·c Ä‘á»‹nh: True
# Náº¿u báº­t â†’ thÃªm:
# delta: tá»‘c Ä‘á»™ thay Ä‘á»•i (1st-order)
# delta-delta: gia tá»‘c thay Ä‘á»•i (2nd-order)
# ğŸ“Œ GiÃºp tÄƒng kháº£ nÄƒng nháº­n biáº¿t giai Ä‘iá»‡u Ä‘ang lÃªn/xuá»‘ng, biáº¿n Ä‘á»™ng
def extract_mfcc_pro(file_path,
                     sr=44100,
                     n_mfcc=40,
                     n_fft=4096,
                     hop_length=256,
                     use_delta=True):

    # Load audio vá»›i sampling rate cao
    y, sr = librosa.load(file_path, sr=sr)

    # Normalize biÃªn Ä‘á»™
    y = librosa.util.normalize(y)

    # Cáº¯t khoáº£ng láº·ng (silence)
    y, _ = librosa.effects.trim(y)

    # Pre-emphasis filter (lÃ m ná»•i báº­t táº§n sá»‘ cao)
    pre_emphasis = 0.97
    y_preemph = np.append(y[0], y[1:] - pre_emphasis * y[:-1])

    # TÃ­nh MFCC
    mfcc = librosa.feature.mfcc(
        y=y_preemph,
        sr=sr,
        n_mfcc=n_mfcc,
        n_fft=n_fft,
        hop_length=hop_length
    )

    if use_delta:
        # TÃ­nh delta vÃ  delta-delta
        delta = librosa.feature.delta(mfcc)
        delta2 = librosa.feature.delta(mfcc, order=2)
        mfcc_all = np.vstack([mfcc, delta, delta2])
    else:
        mfcc_all = mfcc

    # Tráº£ vá» vector trung bÃ¬nh
    mfcc_mean = mfcc_all.mean(axis=1)

    return mfcc_mean


# TÃ­nh MFCC siÃªu cáº¥p (ultra) vá»›i Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a
def extract_mfcc_ultra(file_path,
                       sr=48000,
                       n_mfcc=40,
                       n_fft=4096,
                       hop_length=256,
                       use_delta=True,
                       apply_cmvn=False):
    """
    TrÃ­ch xuáº¥t MFCC siÃªu cáº¥p: Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a
    """

    # Load & normalize
    y, _ = librosa.load(file_path, sr=sr)
    y = librosa.util.normalize(y)

    # Trim silence (chÃ­nh xÃ¡c hÆ¡n)
    y, _ = librosa.effects.trim(y, top_db=30)

    # Pre-emphasis filter
    pre_emphasis = 0.97
    y_preemph = np.append(y[0], y[1:] - pre_emphasis * y[:-1])

    # MFCC
    mfcc = librosa.feature.mfcc(
        y=y_preemph,
        sr=sr,
        n_mfcc=n_mfcc,
        n_fft=n_fft,
        hop_length=hop_length
    )

    # ThÃªm log-energy (dÃ²ng Ä‘áº§u tiÃªn lÃ  tá»•ng nÄƒng lÆ°á»£ng khung)
    log_energy = librosa.feature.rms(y=y_preemph, hop_length=hop_length).flatten()
    log_energy = np.log1p(log_energy)  # log(1 + E)
    log_energy = np.expand_dims(log_energy, axis=0)
    mfcc = np.vstack([log_energy, mfcc])  # giá» lÃ  (n_mfcc+1, T)

    if use_delta:
        delta = librosa.feature.delta(mfcc)
        delta2 = librosa.feature.delta(mfcc, order=2)
        mfcc = np.vstack([mfcc, delta, delta2])  # (n_feat*3, T)

    if apply_cmvn:
        # Apply Cepstral Mean Variance Normalization
        mfcc = (mfcc - np.mean(mfcc, axis=1, keepdims=True)) / \
               (np.std(mfcc, axis=1, keepdims=True) + 1e-6)

    mfcc_mean = mfcc.mean(axis=1)
    return mfcc_mean




# === SO KHá»šP MFCC + TEMPO + CENTROID ===
# ğŸ¯ Nháº­n diá»‡n cá»±c chÃ­nh xÃ¡c (báº£n gá»‘c 100%)	MFCC â‰¥ 0.95, tempo â‰¤ 5, centroid â‰¤ 150
# ğŸµ Nháº­n diá»‡n báº£n phá»‘i láº¡i	                MFCC â‰¥ 0.85, tempo â‰¤ 20, centroid â‰¤ 500
# ğŸ™ï¸ Nháº­n diá»‡n ngÆ°á»i huÃ½t sÃ¡o/hÃ¡t láº¡i	    MFCC â‰¥ 0.75, tempo â‰¤ 25, centroid bá» qua
def find_best_match_whistle(query_vec, query_tempo, query_centroid, database,
                            mfcc_weight=0.55, tempo_weight=0.3, centroid_weight=0.15):
    candidates = []

    for song in database:
        db_vec = np.array(song["mfcc"])


        sim_mfcc = np.dot(query_vec, song['mfcc']) / (
                np.linalg.norm(query_vec) * np.linalg.norm(song['mfcc'])
        )

        # sim_mfcc = np.dot(query_vec, db_vec) / (np.linalg.norm(query_vec) * np.linalg.norm(db_vec))
        # sim_mfcc = cosine_similarity([query_vec], [db_vec])[0][0]

        tempo_diff = abs(query_tempo - song["tempo"])
        centroid_diff = abs(query_centroid - song["spectral_centroid"])

        # Debug output
        print(f"\nğŸµ {song['title']} - {song['artist_name']}")
        print(f"MFCC: {sim_mfcc:.3f}, Tempo Diff: {tempo_diff:.2f} BPM, Centroid Diff: {centroid_diff:.2f} Hz")

        # Sá»­ dá»¥ng threshold gáº§n sÃ¡t 100%
        # or centroid_diff <= 50
        if sim_mfcc >= 0.98 or tempo_diff <= 2:
            candidates.append((song, 0.99))
            continue

        # Lá»c theo threshold
        if sim_mfcc >= 0.75 and tempo_diff <= 15 and centroid_diff <= 350:
            # Chuáº©n hoÃ¡ cÃ¡c diff vá» [0â€“1] rá»“i chuyá»ƒn thÃ nh Ä‘iá»ƒm
            tempo_score = 1 - (tempo_diff / 15)
            centroid_score = 1 - (centroid_diff / 350)

            score = sim_mfcc * mfcc_weight + tempo_score * tempo_weight + centroid_score * centroid_weight
            candidates.append((song, score))

    # Tráº£ vá» bÃ i cÃ³ tá»•ng Ä‘iá»ƒm cao nháº¥t
    if candidates:
        candidates.sort(key=lambda x: x[1], reverse=True)
        print("\nğŸ” CÃ¡c bÃ i hÃ¡t kháº£ thi:")
        for song, score in candidates:
            print(f"  - {song['title']} - {song['artist_name']}: {score*100:.2f}%")

        best_song = candidates[0][0]
        print(f"\nâœ…âœ…âœ… Nháº­n diá»‡n: {best_song['title']} - {best_song['artist_name']}")
        return best_song
    else:
        print("\nâŒ KhÃ´ng cÃ³ bÃ i nÃ o Ä‘áº¡t Ä‘á»§ Ä‘iá»u kiá»‡n threshold.")
        return None


# === CHáº Y TOÃ€N Bá»˜ ===
if __name__ == "__main__":
    record_audio()
    mfcc, tempo, centroid = extract_features("recorded.wav")
    db = load_database("fma_20_songs_db.json")
    find_best_match_whistle(mfcc, tempo, centroid, db)

